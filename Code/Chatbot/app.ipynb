{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing All Required Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salehahmad/Documents/Self_Done_Work/Daniel/env/lib/python3.11/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "/home/salehahmad/Documents/Self_Done_Work/Daniel/env/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chatbot import RAGChatbot\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the RAG chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salehahmad/Documents/Self_Done_Work/Daniel/env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/salehahmad/Documents/Self_Done_Work/Daniel/env/lib/python3.11/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "chatbot = RAGChatbot(\n",
    "    pinecone_api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    index_name='test',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below cell has code to ingest data into the pinecone vector database\n",
    "## Note: Only uncomment and run when you have to really ingest the data from the Data directory (which has all the relavant files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatbot.ingest_data('../../Data', empty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below cell is used to query the RAG chatbot\n",
    "## You can test the responses for different values of \n",
    "- k: The number of documents to retrieve from the vector database. You can input any natural number >= 1\n",
    "- rerank: Whether to rerank the retrieved documents or not. Possible inputs are true and false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = chatbot.query_chatbot(input(), k=15, rerank=True) #the input() will ask you to enter the query\n",
    "# print(response['response'])\n",
    "\n",
    "# reranked_docs = response['context_docs']\n",
    "# for docs in reranked_docs:\n",
    "#     print(docs.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    'Who is daniel?',\n",
    "    'Who are you?',\n",
    "    'What is your job?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salehahmad/Documents/Self_Done_Work/Daniel/env/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daniel M. Ringel is an Assistant Professor of Marketing at the Kenan-Flagler Business School, which is part of the University of North Carolina at Chapel Hill in the USA. He has authored or co-authored articles in academic journals, including the Journal of Marketing Research. If you need to contact him, his email is dmr@unc.edu.\n",
      "{'source': '../../Data/3 Published Papers/for_Website/Ringel-2023-Multimarket-Membership-Mapping-JMR.pdf'}\n",
      "{'source': '../../Data/3 Published Papers/for_Embedding/Ringel-2023-Multimarket_Membership_Mapping.docx'}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salehahmad/Documents/Self_Done_Work/Daniel/env/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "100%|██████████| 1/1 [00:00<00:00, 104.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am Wagner, a highly intelligent and friendly AI assistant. I don’t have an age group or gender as I am an artificial intelligence. How can I assist you today?\n",
      "{'source': '../../Data/3 Published Papers/for_Embedding/Ringel-2023-Multimarket_Membership_Mapping.docx'}\n",
      "{'source': '../../Data/3 Published Papers/for_Embedding/Ringel-2023-Multimarket_Membership_Mapping.docx'}\n",
      "{'source': '../../Data/3 Published Papers/for_Website/Ringel-2023-Multimarket-Membership-Mapping-JMR.pdf'}\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salehahmad/Documents/Self_Done_Work/Daniel/env/lib/python3.11/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the context of your research, the relevance of each question to your work involving marketing and AI/ML can be sorted as follows:\n",
      "\n",
      "1. **Question 12:** “At price comparison websites I view products ...”  \n",
      "   - This question is highly relevant to your research because it directly relates to consumer behavior and decision-making in a marketing context. Understanding how consumers interact with price comparison websites can provide valuable insights for data-driven marketing strategies enhanced by AI/ML.\n",
      "\n",
      "2. **Question 13:** The context is a window around a focal word containing the words that appear before and after it.\n",
      "   - This question pertains to a fundamental concept in natural language processing (NLP), which is a key area within AI/ML. While it is not directly about marketing, understanding context windows is crucial for developing AI models that can analyze and interpret textual data, which can be applied to marketing analytics.\n",
      "\n",
      "3. **Input: What is your job?**\n",
      "   - This question is less directly related to your research vision but could still be relevant if you are considering user interactions or profiles as part of your data collection and analysis. Understanding job roles might help in segmenting data or tailoring marketing strategies.\n",
      "\n",
      "So, the sorted order from most to least relevant would be:\n",
      "\n",
      "1. Question 12\n",
      "2. Question 13\n",
      "3. Input: What is your job?\n",
      "\n",
      "This ordering takes into account the direct application of each question to your research goals in advancing data-driven marketing through AI and ML.\n",
      "{'source': '../../Data/CV/Ringel_Daniel_CV_V1.docx'}\n",
      "{'source': '../../Data/3 Published Papers/for_Embedding/Ringel-2023-Multimarket_Membership_Mapping.docx'}\n",
      "{'source': '../../Data/3 Published Papers/for_Website/Ringel-2023-Multimarket-Membership-Mapping-JMR.pdf'}\n",
      "{'source': '../../Data/3 Published Papers/for_Embedding/Ringel-2023-Multimarket_Membership_Mapping.docx'}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "    response = chatbot.query_chatbot(prompt, k=15, rerank=True) #the input() will ask you to enter the query\n",
    "    print(response['response'])\n",
    "\n",
    "    reranked_docs = response['context_docs']\n",
    "    for docs in reranked_docs:\n",
    "        print(docs.metadata)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
